---
layout: blog
section-type: blog
title: Blog
sitemap:
  priority: 1.0
---
# 07rd March 2022

Had many meetings. Probably today one of the most important of my working life, up to now. Let's see.

In the meantime I am exhausted, it's 00.46am, I worked all day and I have just finished preparing the schedule for tomorrow evening's interview. Here it is, enjoy and see you:

Could you give us your history, in terms of research interests, concrete career milestones and current open questions and strategy to tackle them, in a few sentences?

Could you describe your research group, thelearningdock? Is it made of all matematicians? Or also computer scientists? Engineers?

Kernel-Based Learning for Dynamical Systems: why should dynamical systems people be interested in Machine Learning? And why particularly Kernel Methods, and not the more popular Neural Networks? Is it a closed field trying to explain the representative power of Deep Neural Networks using kernel methods?

What is a Reproducing Kernel Hilbert Space? What are occupation kernels?

Why are Hilbert (and Banach? Fock?) spaces the main place to work with differential operators? Why is the property of being Densely Defined Operators important in your work? Is this related to finite diverging time systems like f(x)=1 + x^2?

Is there a conceptual relation between Hilbert Spaces and Reimmanian Manifolds?

Why is the Koopman operator so popular in the data-driven dynamical system community?

What is the intuitive meaning of fractional differentiation?

DMD and Koopman Theory for fractional order systems. Do you think fractional calculus could be used in tackling the problem of deterministic chaos? Related to ergodic theory and the works by Mezic, it seems time averages along trajectories are eigenfunctions. Do you think Introducing some kind of memory (e.g., time-delay embedding: Brunton, Giannakis..) in such systems could help understand them? Maybe chaos and coloured/correlated noise are related concepts?
What is the role of adjoint relations in the context of Caputo fractional derivative?

How does Nonlinear System ID for fractional order systems work?

THE OCCUPATION KERNEL METHOD FOR NONLINEAR SYSTEM IDENTIFICATION: it seems you replace derivatives with integrals, making the algorithm less sensitive to measurement noise, how does it work? Relation with SINDy? If the world is nonlinear and our math likes linearity, doesn't this say something about the wrong ideas at the core of our math? Similar to this, I've been thinking, inspired by the Giorgio Parisi works on spin glasses: chaotic dynamics leads to fractal geometry: shoulnd't our description of these fenomena reflect the emerging properties?

What is the fractional laplacian? And what is a pseudospectral method and when is this preferred over spectral methods (e.g., Galerkin methods?)? Why is the RBF a kernel method? Would you call Polynomial Chaos Expansion a kernel method as well? You talk about FFT in this context: I am thinking about the inverse scattering transform here, could that or something related to it be used to deal with fractional PDEs as well?

Why do you talk about the Liovuille operator in the context of DMD instead of the Koopman Operator? In this way is your operator perspective more general than Koopman theory? Is your methodology applicable to stochastic systems as well (e.g., the Fokker-Plank operator)? What is the high-order Liouville Operator?

You introduce the Gram matrix: have you ever dealt with the pre-image problem? E.g., in Kernel-PCA?
Does the work Dynamic Mode Decomposition for Continuous Time Systems with the Liouville Operator make use of the kernel trick for the computation of the operator and of the Gram Matrix? If so, do you think the same could be done starting from a symbolic dynamics instead of from data? We have been struggling with this point. Should we give up and sample the phase space to generate synthetic data to build a model using something like your methodology here? We've been building on Klus et al. for this.

Similar to this, as I wrote you months ago: the inner products in Polynomial Chaos Expansion are evaluated by quadrature: do you think the kernel trick can be generalized for something like <phi(x), f(phi(x))> = g(k(x,x)) ? At least for some dynamics f(x)?

Usage of YouTube: why do you have a Youtube channel? What is your goal? Your channel is difficult for me, that I been in university (BSc, MSc, PhD) for 7 years. Why are you not attending specialized conferences? Do you think the youtube "form" and the official conferences "substances" can be integrated into a new way of communicating science, both to specialized audiences and to the big public? Do you push yourself to make the contents of your channel accessible or do you prefer to be formally consistent?
